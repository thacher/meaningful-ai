# ==========================================
# Meaningful AI - Environment Configuration
# ==========================================
# This is a LOCAL-ONLY application that uses Ollama for AI responses
# No cloud AI services are required - all data stays on your machine!

# ==========================================
# Supabase Configuration (OPTIONAL)
# ==========================================
# The app works perfectly with local storage!
# Only set these if you want cloud persistence
# Get from: https://supabase.com/dashboard

# Your Supabase project URL
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co

# Your Supabase anon/public key
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key_here

# ==========================================
# Admin Configuration
# ==========================================
# Password to access the admin dashboard at /admin
# CHANGE THIS IN PRODUCTION!
ADMIN_PASSWORD=admin123

# ==========================================
# App Configuration
# ==========================================
# Base URL for your application
NEXT_PUBLIC_APP_URL=http://localhost:3000

# ==========================================
# Setup Instructions
# ==========================================
# 1. Copy this file to .env.local
# 2. Optionally add Supabase credentials for cloud storage
# 3. Change the admin password for security
# 4. Install Ollama for local AI: https://ollama.ai/
# 5. Run: npm run dev
# 
# The app works immediately with local storage - no database required!
# 
# LOCAL AI SETUP:
# - Install Ollama from https://ollama.ai/
# - Run: ollama pull llama3.1:8b (or any model you prefer)
# - The app will automatically use Ollama for AI responses
# - If Ollama is not available, it falls back to wisdom-based responses
